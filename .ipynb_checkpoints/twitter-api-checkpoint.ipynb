{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'helo ths is me (hi) -everyone (#test) (from: potus OR tumblr) (to: snapchat OR bitcoin) (stocks OR elon) lang:en until:2007-02-02 to:2006-01-01 '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_query(all_w,this_exact,any_w,none_w,hash_w,lang_w,from_twit,to_twit,mentions,from_date,to_date):\n",
    "    final_query = \"\"\n",
    "    for str in all_w:\n",
    "        final_query = final_query + str + \" \"\n",
    "    if (this_exact):\n",
    "        final_query = final_query + this_exact + \" \"\n",
    "    count =0\n",
    "    for str in any_w:\n",
    "        count += 1\n",
    "        if (count ==1):\n",
    "            final_query = final_query + \"(\"\n",
    "        if (str == any_w[-1]):\n",
    "            final_query = final_query + str + \") \"\n",
    "        else:\n",
    "            final_query = final_query + str + \" OR \"\n",
    "    for str in none_w:\n",
    "        final_query += \"-\" + str + \" \"\n",
    "    count = 0\n",
    "    for str in hash_w:\n",
    "        count += 1\n",
    "        if (count ==1):\n",
    "            final_query = final_query + \"(\"\n",
    "        if (str == hash_w[-1]):\n",
    "            final_query = final_query + str + \") \"\n",
    "        else:\n",
    "            final_query = final_query + str + \" OR \"\n",
    "    count = 0\n",
    "    for str in from_twit:\n",
    "        count += 1\n",
    "        if (count ==1):\n",
    "            final_query = final_query + \"(from: \"\n",
    "        if (str == from_twit[-1]):\n",
    "            final_query = final_query + str + \") \"\n",
    "        else:\n",
    "            final_query = final_query + str + \" OR \"\n",
    "    count = 0\n",
    "    for str in to_twit:\n",
    "        count += 1\n",
    "        if (count ==1):\n",
    "            final_query = final_query + \"(to: \"\n",
    "        if (str == to_twit[-1]):\n",
    "            final_query = final_query + str + \") \"\n",
    "        else:\n",
    "            final_query = final_query + str + \" OR \"\n",
    "    count = 0\n",
    "    for str in mentions:\n",
    "        count += 1\n",
    "        if (count ==1):\n",
    "            final_query = final_query + \"(\"\n",
    "        if (str == mentions[-1]):\n",
    "            final_query = final_query + str + \") \"\n",
    "        else:\n",
    "            final_query = final_query + str + \" OR \"\n",
    "    if (lang_w):\n",
    "        final_query += \"lang:\" + lang_w + \" \"\n",
    "    if (to_date):\n",
    "        final_query += \"until:\" + to_date + \" \"\n",
    "    if (from_date):\n",
    "        final_query += \"to:\" + from_date + \" \"\n",
    "    return final_query\n",
    "\n",
    "final_query=create_query(['helo','ths'], \"is me\", [\"hi\"], [\"everyone\"], [\"#test\"], \"en\", ['potus','tumblr'], ['snapchat','bitcoin'], ['stocks','elon'], '2006-01-01', '2007-02-02')\n",
    "final_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install snscrape\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "query = \"(MSFT) -dog until:2022-03-06 since:2006-12-18\"\n",
    "tweets = []\n",
    "limit = 10000\n",
    "i = 0\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    i = i+1\n",
    "    # print(vars(tweet))\n",
    "    # break\n",
    "    if(i % 1000 == 0):\n",
    "        print(\"total extracted is: \",i)\n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "    else:\n",
    "        tweets.append([tweet.date, tweet.username, tweet.content])\n",
    "pd.set_option(\"display.max_colwidth\", 10000)      \n",
    "df = pd.DataFrame(tweets, columns=['Date', 'User', 'Tweet'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#program to filter tweets------------------\n",
    "df_tweet = df['Tweet']\n",
    "single_tweetlist = []\n",
    "final_tweet_list = []\n",
    "for i in range(0,len(df)):\n",
    "    tweet_fil = df_tweet[i] # single tweet from list\n",
    "    tw_split_list = tweet_fil.split() #split single tweet\n",
    "    \n",
    "    \n",
    "    single_tweetlist = [] # refresh list to store new tweet\n",
    "    for tw_split in tw_split_list: #go through each word\n",
    "        print(tw_split)\n",
    "        if(tw_split[0] != '@' and tw_split.count('https://t.')==0): \n",
    "            \n",
    "            single_tweetlist.append(tw_split)\n",
    "    print(\"\\n------------------------------------\",i,\"-------------------------------------------------------\")\n",
    "    \n",
    "    #add up string\n",
    "    tweet_single = ''\n",
    "    count_word = 0\n",
    "    for single_tweet in single_tweetlist:\n",
    "        if(count_word == 0):\n",
    "            tweet_single = single_tweet\n",
    "            count_word= 1\n",
    "        else:\n",
    "            tweet_single = tweet_single+\" \"+single_tweet\n",
    "    print(tweet_single) \n",
    "    final_tweet_list.append(tweet_single)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(final_tweet_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-20 06:34:51.394879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-20 06:34:51.446436: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-08-20 06:34:51.446486: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy.language import Language\n",
    "\n",
    "import spacy\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "conf=0.98\n",
    "nlp = spacy.load('en_core_web_sm')  # 1\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last=True)\n",
    "language_filter_text=[]\n",
    "for text in final_tweet_list:\n",
    "    doc = nlp(text) #3\n",
    "    detect_language = doc._.language #4\n",
    "    if 'en'== detect_language[\"language\"] and detect_language[\"score\"]>conf :\n",
    "        language_filter_text.append(text)\n",
    "    else:\n",
    "        language_filter_text.append(\"Remove This tweet\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_tweets = pd.DataFrame(language_filter_text, columns=['Tweets'])\n",
    "filter_tweets.to_csv(\"Final_tweets_msft.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
